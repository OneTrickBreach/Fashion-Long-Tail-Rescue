# ============================================================
# Central Configuration â€” Seeing the Unseen
# CS7180 Applied Deep Learning | Ishan, Elizabeth, Nishant
# ============================================================
# Edit paths & hyper-parameters here; they propagate everywhere
# via `src/utils/helpers.py::load_config()`.

project:
  name: "seeing-the-unseen"
  seed: 42

paths:
  raw_data:       "h-and-m-personalized-fashion-recommendations"
  sampled_data:   "data/sampled"
  embeddings:     "data/embeddings"
  checkpoints:    "checkpoints"
  outputs:        "outputs"

sampling:
  # Fraction of transactions to keep for local development
  fraction: 0.15                   # 15% of users (beefed up from 5%)
  # Minimum interactions per user to retain
  min_interactions: 5
  # Keep only the last N weeks of transactions (temporal pruning)
  temporal_weeks: 12               # 12 weeks (beefed up from 6)
  # Articles with fewer than this many total purchases are "long tail"
  long_tail_threshold: 10

embedding:
  backbone: "resnet50"             # Pre-trained CNN for visual features
  dim: 2048                        # Output embedding dimension
  batch_size: 64
  device: "cuda"                   # "cuda" or "cpu"

villain:
  # Baseline: position-aware sequential recommender (text-only)
  model_type: "sasrec"             # Options: sasrec, elo_ranking
  max_seq_len: 50
  hidden_dim: 128                  # beefed up from 64
  num_heads: 4                     # beefed up from 2
  num_layers: 3                    # beefed up from 2
  dropout: 0.2
  lr: 0.001
  weight_decay: 0.01               # AdamW L2 regularisation
  epochs: 50                       # beefed up from 30
  batch_size: 256
  checkpoint_every: 5              # Save checkpoint every N epochs
  patience: 10                     # beefed up from 7

hero:
  # Main model: multimodal BST + Attribute-Aware Contrastive head
  max_seq_len: 50
  hidden_dim: 128
  num_heads: 4
  num_layers: 3
  dropout: 0.1
  lr: 0.0005
  epochs: 50
  batch_size: 128
  contrastive:
    temperature: 0.07
    hard_negatives: 10
    weight: 0.3                    # Loss weight for contrastive term

evaluation:
  k: 12                           # nDCG@K, top-K recommendations
  metrics:
    - ndcg
    - mrr
    - catalog_coverage
