# Week 1 Plan ‚Äî Ishan Biswas
## Phase 1: Data Engineering & Custom Baseline (Feb 15 ‚Äì Feb 21)

> **Role:** Transformer Architect & Loss Tuning  
> **Branch:** `week1-ishan`  
> **Tools:** PyTorch, CUDA, NumPy, Pandas

---

## Overview

Week 1 establishes the foundation for the entire project.  My responsibilities fall into
two buckets:

1. **Local Environment** ‚Äî confirm PyTorch + CUDA are functional and the full pipeline
   can train on the sampled dataset within local RAM/VRAM limits.
2. **The Villain Baseline** ‚Äî build and evaluate a **Position-Aware Sequential Recommender
   (SASRec variant)** that is deliberately blind to visual features.  This becomes the
   "control" that the Hero must beat in Phase 2.

All hyperparameters and paths come from `config.yaml` (single source of truth per
`rules.md ¬ß2`).  All derived data is written to `data/sampled/` ‚Äî raw files in
`h-and-m-personalized-fashion-recommendations/` are **never** modified (`rules.md ¬ß4`).

---

## Task Breakdown

### 1. Environment Verification  *(~0.5 day)*

| # | Sub-task | Details |
|---|----------|---------|
| 1a | Activate `.venv` and verify packages | Run `python -c "import torch; print(torch.cuda.is_available())"` ‚Äî must print `True`. |
| 1b | Confirm `config.yaml` loads | Run `from src.utils.helpers import load_config; cfg = load_config()` and inspect. |
| 1c | Verify GPU memory | Run `torch.cuda.get_device_properties(0)` ‚Äî note total VRAM for batch-size tuning. |
| 1d | Add any missing packages | e.g., `pyyaml`, `pandas`, etc.  Update `requirements.txt` after each install. |

**Deliverable:** A passing "smoke test" that imports all project modules and touches the GPU.

---

### 2. Data Sampling Pipeline  *(~1 day)*

> **Dependency:** Elizabeth's preprocessing  (may run in parallel since sampling can use raw CSVs directly).

| # | Sub-task | Details |
|---|----------|---------|
| 2a | Implement `src/data/sampler.py::create_sample()` | Read `transactions_train.csv` in chunks (`pd.read_csv(..., chunksize=500_000)`).  Apply 5 % stratified sample preserving head/torso/tail bins.  Filter users with < 5 interactions (`config.yaml ‚Üí sampling.min_interactions`). |
| 2b | Write sampled CSVs | Save `transactions_sampled.csv`, `articles_sampled.csv`, `customers_sampled.csv` to `data/sampled/`. |
| 2c | Long-tail labeling | Add a `is_long_tail` boolean column to the articles sample (articles with < 10 total purchases).  This supports Nishant's Visibility Skew chart. |
| 2d | Distribution analysis | Print & log item-frequency distributions before/after sampling to verify the long-tail shape is preserved. |

**Key technical considerations:**
- `transactions_train.csv` is **3.5 GB** ‚Äî must use chunked I/O, never `pd.read_csv()` on the whole file.
- Convert IDs to `int32` for RAM savings (per Elizabeth's plan, but we need this regardless).
- Temporal pruning: keep only the last 4‚Äì6 weeks of transactions (configurable in `config.yaml`).

**Deliverable:** `data/sampled/` populated with manageable CSVs (~5 % of original).

---

### 3. Dataset & DataLoader  *(~1 day)*

| # | Sub-task | Details |
|---|----------|---------|
| 3a | Implement `TransactionDataset` class in `src/data/dataset.py` | Each sample = one user's chronological purchase sequence (item IDs).  Pad/truncate to `max_seq_len = 50`.  Positional indices as a second tensor. |
| 3b | Train / Val / Test split | Temporal split: last purchase ‚Üí test, second-to-last ‚Üí val, rest ‚Üí train.  This follows the leave-one-out evaluation protocol standard in sequential rec. |
| 3c | Implement `build_dataloaders()` | Returns `(train_loader, val_loader, test_loader)` using `torch.utils.data.DataLoader` with configurable `batch_size`. |
| 3d | Negative sampling | For each positive next-item, sample *N* negatives from the catalog.  Needed for pairwise loss (BPR) or cross-entropy. |

**Matrix shapes (input to Villain):**
```
item_seq:   (batch_size, max_seq_len)       ‚Äî int64 item IDs
positions:  (batch_size, max_seq_len)       ‚Äî int64 position indices [0 .. seq_len-1]
labels:     (batch_size,)                   ‚Äî int64 next-item ground truth
```

**Deliverable:** Working DataLoaders that feed batches to the model.

---

### 4. Villain Model Architecture  *(~1.5 days)*

> This is the core deliverable for Week 1.

| # | Sub-task | Details |
|---|----------|---------|
| 4a | Item + positional embeddings | `nn.Embedding(num_items, hidden_dim)` + `nn.Embedding(max_seq_len, hidden_dim)`.  Sum them (SASRec style). |
| 4b | Transformer encoder stack | `nn.TransformerEncoder` with `num_layers=2`, `num_heads=2`, `hidden_dim=64` (from `config.yaml ‚Üí villain`).  Causal mask so position *t* only attends to ‚â§ *t*. |
| 4c | Prediction head | Inner product of final hidden state with all item embeddings ‚Üí `(batch_size, num_items)` logits.  Apply softmax for next-item probabilities. |
| 4d | Position-bias injection | The "ELO / Bubblesort" flavour: multiply logits by a learned position-bias vector so that items appearing in high-frequency positions get boosted.  This deliberately biases toward popular items, burying the long tail. |
| 4e | Loss function | Cross-entropy over the full catalog, or BPR (Bayesian Personalized Ranking) pairwise loss.  Start with CE, switch to BPR if CE is too slow over a large item vocabulary. |

**Architecture diagram:**
```
Input IDs ‚îÄ‚ñ∫ Item Embed ‚îÄ‚îÄ‚îê
                          ‚îú‚îÄ + ‚îÄ‚ñ∫ Transformer (√ó2 layers) ‚îÄ‚ñ∫ Final Hidden ‚îÄ‚ñ∫ dot(Item Embeds) ‚îÄ‚ñ∫ logits
Position  ‚îÄ‚ñ∫ Pos  Embed ‚îÄ‚îÄ‚îò                                                      √ó pos_bias
```

**Deliverable:** `VillainModel` class that accepts `(item_seq, positions)` and returns `(batch_size, num_items)` scores.

---

### 5. Training Loop  *(~1 day)*

| # | Sub-task | Details |
|---|----------|---------|
| 5a | Implement `src/villain/trainer.py::train_villain()` | Standard PyTorch training loop: forward ‚Üí loss ‚Üí backward ‚Üí optimizer step. |
| 5b | Optimizer & scheduler | Adam with `lr = 0.001`.  Optional: ReduceLROnPlateau or CosineAnnealing. |
| 5c | Validation & early stopping | Evaluate nDCG@12 on val set every epoch; stop if no improvement for 5 epochs. |
| 5d | Checkpoint saving | Save best model to `checkpoints/villain_best.pt`.  Git-ignore checkpoints (`rules.md ¬ß5`). |
| 5e | Logging | Use `src/utils/helpers.py::setup_logging()`.  Print epoch, loss, val metrics per epoch. |

**Deliverable:** End-to-end trainable Villain that converges on the sampled data.

---

### 6. Evaluation Hookup  *(~0.5 day)*

| # | Sub-task | Details |
|---|----------|---------|
| 6a | Wire up `src/utils/metrics.py` | Confirm nDCG@12 and MRR implementations are correct ‚Äî Nishant owns these, but I need to call them in the Villain eval. |
| 6b | Full eval pass | After training, run the Villain on the test set and report nDCG@12, MRR, and Catalog Coverage. |
| 6c | Baseline results log | Write results to `outputs/villain_baseline_results.json` for comparison with the Hero later. |

**Deliverable:** Printed & saved evaluation scores for the Villain baseline.

---

### 7. Decision Log & Documentation  *(ongoing)*

| # | Sub-task | Details |
|---|----------|---------|
| 7a | Decision log | Document *why* we chose a position-biased baseline (per `plan.md`): it simulates real e-commerce popularity bias so the Hero has a clear "injustice" to fix. |
| 7b | Matrix shapes doc | Update `docs/matrix_shapes.md` with all tensor dimensions for the Villain. |
| 7c | Code docstrings | Every new `.py` file follows the format in `rules.md ¬ß3`: module docstring with purpose, team member, key classes/functions. |

---

## Dependencies on Teammates

| Teammate | What I need from them | Blocking? |
|----------|----------------------|-----------|
| **Elizabeth** | `int32` preprocessed transactions (temporal pruning, memory pivot) | **No** ‚Äî I can sample from raw CSVs and re-sample later if her format changes. |
| **Nishant** | nDCG@12, MRR metric implementations in `src/utils/metrics.py` | **No** ‚Äî I can write a quick placeholder and swap in his version. |

---

## Risk & Mitigation

| Risk | Impact | Mitigation |
|------|--------|------------|
| Full-catalog softmax is too slow (105k items) | Training won't converge in time | Use sampled softmax or BPR pairwise loss instead of full CE. |
| 3.5 GB CSV blows up RAM during sampling | Crashes / swap thrashing | Chunked reading with `chunksize=500_000`. |
| GPU VRAM insufficient for batch_size=256 | CUDA OOM | Reduce batch_size; use gradient accumulation. |
| Leave-one-out split gives too few train sequences for rare users | Poor long-tail recall | Enforce `min_interactions ‚â• 5` during sampling. |

---

## Suggested Execution Order

```
Day 1 (Feb 16):  Tasks 1 (env) + 2 (sampling pipeline)
Day 2 (Feb 17):  Task 3 (dataset / dataloaders)
Day 3 (Feb 18):  Task 4 (Villain model architecture)
Day 4 (Feb 19):  Task 5 (training loop) ‚Äî first training run overnight
Day 5 (Feb 20):  Task 6 (evaluate baseline) + Task 7 (docs & decision log)
Day 6 (Feb 21):  Buffer / bug fixes / coordination with Elizabeth & Nishant
```

---

## Success Criteria (End of Week 1)

- [x] `.venv` activates, PyTorch + CUDA confirmed working
- [x] `data/sampled/` contains ‚â§ 5 % subset with preserved long-tail distribution
- [ ] `VillainModel` trains to convergence on the sampled data
- [ ] Baseline nDCG@12, MRR, and Catalog Coverage are recorded
- [ ] Decision log explains the position-biased baseline choice
- [ ] All code follows `rules.md` (docstrings, config-driven, no hard-coded paths)

---

## Progress Journal

### Day 1 ‚Äî Feb 16, 2026

#### ‚úÖ Task 1: Environment Verification ‚Äî DONE

| Component | Value |
|-----------|-------|
| PyTorch | 2.10+cu128 |
| CUDA | 12.8 |
| GPU | NVIDIA GeForce RTX 5070 Ti |
| VRAM | 11.9 GB |
| NumPy | 2.3.5 |
| Pandas | 3.0.0 |

All utility functions (`load_config`, `set_seed`, `get_device`) confirmed working.

#### ‚úÖ Task 2: Data Sampling Pipeline ‚Äî DONE

**What was built:** `src/data/sampler.py` ‚Äî full stratified long-tail sampler with:
- 2-pass chunked reading of the 3.5 GB transactions CSV (chunksize=500k, no OOM)
- Temporal pruning to last 6 weeks (configurable via `config.yaml ‚Üí sampling.temporal_weeks`)
- Stratified user sampling by popularity bin (head / torso / tail)
- Long-tail article labeling (`is_long_tail` column, threshold from config)
- `int32` compact dtypes for article IDs

**Config changes:** Added `temporal_weeks: 6` and `long_tail_threshold: 10` to `config.yaml ‚Üí sampling`.

**Sampled dataset (`data/sampled/`):**

| File | Rows | Notes |
|------|------|-------|
| `transactions_sampled.csv` | 58,971 | 5,930 users ¬∑ 12,559 articles |
| `articles_sampled.csv` | 12,559 | 88.3% flagged as long-tail |
| `customers_sampled.csv` | 5,930 | |

**Date range:** 2020-08-11 ‚Üí 2020-09-22 (6-week window)

**Distribution stats (confirms long-tail preserved):**

| Metric | Value |
|--------|-------|
| Median purchases/item | 2 |
| Mean purchases/item | 4.7 |
| Max purchases/item | 121 |
| Head (80% of txns) | 4,599 articles (36.6%) |
| Torso (next 15%) | 5,011 articles (39.9%) |
| Tail (last 5%) | 2,949 articles (23.5%) |

---

### Day 2‚Äì3 ‚Äî Feb 17, 2026

#### ‚úÖ Task 3: Dataset & DataLoader ‚Äî DONE

**What was built:** `src/data/dataset.py`
- `build_id_maps()` ‚Äî remaps raw 9-digit article IDs to contiguous 0-based indices (PAD=0)
- `TransactionDataset` ‚Äî leave-one-out temporal split:
  - **Train:** sliding-window over prefix (excludes val+test items)
  - **Val:** input = all but last 2, target = second-to-last
  - **Test:** input = all but last, target = last
- `build_dataloaders()` ‚Äî factory returning train/val/test `DataLoader` + metadata dict
- Right-padding to `max_seq_len=50`, position indices, seq_len tracking

| Split | Samples | Batch shape |
|-------|---------|-------------|
| Train | ~46k | `[256, 50]` |
| Val | ~5.9k | `[256, 50]` |
| Test | ~5.9k | `[256, 50]` |

**Vocabulary:** 12,560 items (12,559 articles + PAD token)

#### ‚úÖ Task 4: Villain Model Architecture ‚Äî DONE

**What was built:** `src/villain/model.py` ‚Äî `VillainModel` (SASRec variant)
- Item embedding + position embedding (summed, LayerNorm, dropout)
- `nn.TransformerEncoder` with causal + padding masks (2 layers, 2 heads, dim=64)
- Dot-product prediction head against all item embeddings
- **Learnable `pop_bias`** vector (1 scalar per item) ‚Äî the Villain's deliberate popularity bias
- `predict_top_k()` convenience method for inference
- **919,824 total parameters** ‚Äî lightweight, well within VRAM

Also fixed `src/villain/config.py` with working `get_villain_config()` merge.

**Forward pass verified on GPU:** logits shape `[256, 12560]`, CE loss computable, top-12 predictions working.

---

### Evening Feb 17 ‚Äî Code Review + Task 5

#### üîç Code Review of Tasks 1‚Äì4

Fixes applied:
- **`src/utils/metrics.py`** ‚Äî implemented all 4 metric functions (were all `NotImplementedError`)
- **`src/villain/model.py`** ‚Äî fixed `_init_weights` non-contiguous tensor slice issue, removed unused imports
- **`config.yaml`** ‚Äî added `weight_decay`, `checkpoint_every`, `patience` to villain config

#### ‚úÖ Task 5: Training Loop ‚Äî DONE

**What was built:** `src/villain/trainer.py`
- AdamW optimizer with weight_decay=0.01, ReduceLROnPlateau scheduler
- Gradient clipping (max_norm=1.0) for transformer stability
- Per-epoch validation: nDCG@12, MRR, Catalog Coverage
- **Checkpoint save/resume:**
  - `checkpoints/villain_latest.pt` ‚Äî saved every 5 epochs
  - `checkpoints/villain_best.pt` ‚Äî saved on new best val nDCG@12
  - Auto-resumes from `villain_latest.pt` on startup
  - Stores: model weights, optimizer state, scheduler state, epoch, best_ndcg, full history
- Early stopping (patience=7)
- Final test eval loads best model, saves results to `outputs/villain_baseline_results.json`

**Training command (run from project root with venv activated):**
```powershell
.venv\Scripts\Activate.ps1; python -m src.villain.trainer
```

**Next up (Day 5 ‚Äî Feb 20):** Task 6 ‚Äî Evaluate baseline results + documentation.
